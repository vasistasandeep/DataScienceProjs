{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Wholesale+customers\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sparkContext=sc.sparkContext, sparkSession=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the csv file as a dataframe. And, not as RDD. See the schema of the DF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sqlContext.read.csv('Wholesale customers data.csv',header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### schema of the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Channel: integer (nullable = true)\n",
      " |-- Region: integer (nullable = true)\n",
      " |-- Fresh: integer (nullable = true)\n",
      " |-- Milk: integer (nullable = true)\n",
      " |-- Grocery: integer (nullable = true)\n",
      " |-- Frozen: integer (nullable = true)\n",
      " |-- Detergents_Paper: integer (nullable = true)\n",
      " |-- Delicassen: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "|Channel|Region|Fresh| Milk|Grocery|Frozen|Detergents_Paper|Delicassen|\n",
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "|      2|     3|12669| 9656|   7561|   214|            2674|      1338|\n",
      "|      2|     3| 7057| 9810|   9568|  1762|            3293|      1776|\n",
      "|      2|     3| 6353| 8808|   7684|  2405|            3516|      7844|\n",
      "|      1|     3|13265| 1196|   4221|  6404|             507|      1788|\n",
      "|      2|     3|22615| 5410|   7198|  3915|            1777|      5185|\n",
      "|      2|     3| 9413| 8259|   5126|   666|            1795|      1451|\n",
      "|      2|     3|12126| 3199|   6975|   480|            3140|       545|\n",
      "|      2|     3| 7579| 4956|   9426|  1669|            3321|      2566|\n",
      "|      1|     3| 5963| 3648|   6192|   425|            1716|       750|\n",
      "|      2|     3| 6006|11093|  18881|  1159|            7425|      2098|\n",
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(10,truncate= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use describe to see summary statistics on dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "|summary|           Channel|            Region|             Fresh|              Milk|          Grocery|           Frozen|  Detergents_Paper|        Delicassen|\n",
      "+-------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "|  count|               440|               440|               440|               440|              440|              440|               440|               440|\n",
      "|   mean|1.3227272727272728| 2.543181818181818|12000.297727272728| 5796.265909090909|7951.277272727273|3071.931818181818|2881.4931818181817|1524.8704545454545|\n",
      "| stddev|0.4680515694791137|0.7742724492301002|12647.328865076885|7380.3771745708445|9503.162828994346|4854.673332592367| 4767.854447904201|2820.1059373693965|\n",
      "|    min|                 1|                 1|                 3|                55|                3|               25|                 3|                 3|\n",
      "|    max|                 2|                 3|            112151|             73498|            92780|            60869|             40827|             47943|\n",
      "+-------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding out number of NULL values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel: 0\n",
      "Region: 0\n",
      "Fresh: 0\n",
      "Milk: 0\n",
      "Grocery: 0\n",
      "Frozen: 0\n",
      "Detergents_Paper: 0\n",
      "Delicassen: 0\n"
     ]
    }
   ],
   "source": [
    "names = train.schema.names\n",
    "for name in names:\n",
    "    print(name + \": \" + str(train.where(train[name].isNull()).count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use select to view a single column or a set of chosen columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|Grocery|Frozen|\n",
      "+-------+------+\n",
      "|   7561|   214|\n",
      "|   9568|  1762|\n",
      "|   7684|  2405|\n",
      "|   4221|  6404|\n",
      "|   7198|  3915|\n",
      "+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select('Grocery','Frozen').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use filter to see records with fresh sales more than 50000 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-----+-------+------+----------------+----------+\n",
      "|Channel|Region| Fresh| Milk|Grocery|Frozen|Detergents_Paper|Delicassen|\n",
      "+-------+------+------+-----+-------+------+----------------+----------+\n",
      "|      1|     3| 56159|  555|    902| 10002|             212|      2916|\n",
      "|      1|     3| 56082| 3504|   8906| 18028|            1480|      2498|\n",
      "|      1|     3| 76237| 3473|   7102| 16538|             778|       918|\n",
      "|      1|     3|112151|29627|  18148| 16745|            4948|      8550|\n",
      "|      1|     1| 56083| 4563|   2124|  6422|             730|      3321|\n",
      "|      1|     1| 53205| 4959|   7336|  3012|             967|       818|\n",
      "|      1|     3| 68951| 4411|  12609|  8692|             751|      2406|\n",
      "+-------+------+------+-----+-------+------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.filter(train.Fresh > 50000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create aggregates on channels and regions variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Channel|        avg(Fresh)|\n",
      "+-------+------------------+\n",
      "|      1|13475.560402684563|\n",
      "|      2| 8904.323943661971|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Channel').agg({'Fresh': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Channel|         avg(Milk)|\n",
      "+-------+------------------+\n",
      "|      1|3451.7248322147652|\n",
      "|      2|           10716.5|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Channel').agg({'Milk': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|Channel|Region|        avg(Fresh)|\n",
      "+-------+------+------------------+\n",
      "|      2|     2| 7289.789473684211|\n",
      "|      2|     3| 9831.504761904762|\n",
      "|      1|     2|11650.535714285714|\n",
      "|      1|     1|12902.254237288136|\n",
      "|      1|     3|13878.052132701421|\n",
      "|      2|     1|            5200.0|\n",
      "+-------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupby('Channel','Region').agg({'Fresh': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|Channel|Region|        avg(Fresh)|\n",
      "+-------+------+------------------+\n",
      "|      1|     1|12902.254237288136|\n",
      "|      1|     2|11650.535714285714|\n",
      "|      1|     3|13878.052132701421|\n",
      "|      2|     1|            5200.0|\n",
      "|      2|     2| 7289.789473684211|\n",
      "|      2|     3| 9831.504761904762|\n",
      "+-------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "train.groupby('Channel','Region').agg({'Fresh': 'mean'}).sort(\"Channel\",\"Region\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+------------------+------------------+------------------+\n",
      "|Channel|Region|        avg(Fresh)|         avg(Milk)|      avg(Grocery)|       avg(Frozen)|\n",
      "+-------+------+------------------+------------------+------------------+------------------+\n",
      "|      1|     1|12902.254237288136|3870.2033898305085| 4026.135593220339| 3127.322033898305|\n",
      "|      1|     2|11650.535714285714|           2304.25|            4395.5| 5745.035714285715|\n",
      "|      1|     3|13878.052132701421|3486.9810426540284| 3886.734597156398| 3656.900473933649|\n",
      "|      2|     1|            5200.0|           10784.0|18471.944444444445|2584.1111111111113|\n",
      "|      2|     2| 7289.789473684211|  9190.78947368421|16326.315789473685| 1540.578947368421|\n",
      "|      2|     3| 9831.504761904762|10981.009523809524|15953.809523809523|            1513.2|\n",
      "+-------+------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "cols = ['Fresh','Milk','Grocery','Frozen']\n",
    "exprs = [F.mean(F.col(x)) for x in cols] \n",
    "train.groupby('Channel','Region').agg(*exprs).sort(\"Channel\",\"Region\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+-----------+--------------+-------------+\n",
      "|Channel|Region|count(Fresh)|count(Milk)|count(Grocery)|count(Frozen)|\n",
      "+-------+------+------------+-----------+--------------+-------------+\n",
      "|      1|     1|          59|         59|            59|           59|\n",
      "|      1|     2|          28|         28|            28|           28|\n",
      "|      1|     3|         211|        211|           211|          211|\n",
      "|      2|     1|          18|         18|            18|           18|\n",
      "|      2|     2|          19|         19|            19|           19|\n",
      "|      2|     3|         105|        105|           105|          105|\n",
      "+-------+------+------------+-----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exprs = [F.count(F.col(x)) for x in cols]\n",
    "train.groupby('Channel','Region').agg(*exprs).sort(\"Channel\",\"Region\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use describe to see summary statistics on dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col , column\n",
    "changedTypedf = train.withColumn(\"Channel\", col(\"Channel\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change datatype of Channels to Strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Channel: string (nullable = true)\n",
      " |-- Region: integer (nullable = true)\n",
      " |-- Fresh: integer (nullable = true)\n",
      " |-- Milk: integer (nullable = true)\n",
      " |-- Grocery: integer (nullable = true)\n",
      " |-- Frozen: integer (nullable = true)\n",
      " |-- Detergents_Paper: integer (nullable = true)\n",
      " |-- Delicassen: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "changedTypedf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "|Channel|Region|Fresh| Milk|Grocery|Frozen|Detergents_Paper|Delicassen|\n",
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "|      2|     3|12669| 9656|   7561|   214|            2674|      1338|\n",
      "|      2|     3| 7057| 9810|   9568|  1762|            3293|      1776|\n",
      "|      2|     3| 6353| 8808|   7684|  2405|            3516|      7844|\n",
      "|      1|     3|13265| 1196|   4221|  6404|             507|      1788|\n",
      "|      2|     3|22615| 5410|   7198|  3915|            1777|      5185|\n",
      "|      2|     3| 9413| 8259|   5126|   666|            1795|      1451|\n",
      "|      2|     3|12126| 3199|   6975|   480|            3140|       545|\n",
      "|      2|     3| 7579| 4956|   9426|  1669|            3321|      2566|\n",
      "|      1|     3| 5963| 3648|   6192|   425|            1716|       750|\n",
      "|      2|     3| 6006|11093|  18881|  1159|            7425|      2098|\n",
      "+-------+------+-----+-----+-------+------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "changedTypedf.show(10,truncate= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
