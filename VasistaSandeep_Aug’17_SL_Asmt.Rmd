---
title: "Logistic Regression Model on PL_XSELL dataset"
author: "Sandeep V"
date: "November 18, 2017"
output:
  word_document: default
  pdf_document: default
  html_document: default
---
## Import dataset for modeling and understand the data
```{r Import Data and see Summary}
setwd("C:/Users/vasistas/Documents/From_Mydownloads/PGP-BDA/In_class/3rd_Residency/Assignments")

LR_DF <- read.csv("PL_XSELL.csv", header=TRUE)
View(LR_DF)

summary(LR_DF)

```

####There is no NA so no missing value treatment is required
```{r}

## percentile distribution for all the fields
apply(LR_DF[,sapply(LR_DF, is.numeric)], 
      2, quantile, 
      probs=c(0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 1),
      na.rm=T)


```
```{r}
boxplot(LR_DF$BALANCE , 
        main= "Balance Box Plot" ,
        xlab = "Overall Base"
)


```

####Capping of Balance to 99 percentile
```{r}
LR_DF$BAL_CAP <- 
  ifelse(LR_DF$BALANCE > 3412760.31, 3412760.31, LR_DF$BALANCE)

summary(LR_DF$BAL_CAP)
sd(LR_DF$BAL_CAP)

quantile(LR_DF$BAL_CAP, 
         c(0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 1))

boxplot(LR_DF$BAL_CAP , 
        main= "BAL_CAP Box Plot" ,
        xlab = "Overall Base"
)

```
####To eliminate outliers we will cap balance to 90 percentile
```{r}
LR_DF$BAL_CAP <- 
  ifelse(LR_DF$BALANCE > 1408112.43, 1408112.43, LR_DF$BALANCE)

summary(LR_DF$BAL_CAP)
sd(LR_DF$BAL_CAP)

quantile(LR_DF$BAL_CAP, 
         c(0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 1))

boxplot(LR_DF$BAL_CAP , 
        main= "Balance Box Plot" ,
        xlab = "Overall Base"
)

```


##Build Hypothesis- Hypothesis to be formed  

###We will use following variables in our hypothesis  
####1. BALANCE  
####2. OCCUPATION  
####3. HOLDING_PERIOD   
####4. NO_OF_L_DR_TXNS   
####5. TOT_NO_OF_L_TXNS   
####6. NO_OF_ATM_DR_TXNS   
####7. NO_OF_L_CR_TXNS   
####8. NO_OF_CHQ_DR_TXNS   
####9. AMT_CHQ_DR   
####10. AMT_L_DR   


##Check Hypothesis using Information value

We will not check IV for CUST_ID
```{r}
library(woe)

iv.plot.summary(iv.mult(LR_DF[,!names(LR_DF) %in% c("CUST_ID")],
                        "TARGET",TRUE, verbose = FALSE))

iv <- iv.mult(LR_DF[,!names(LR_DF) %in% c("CUST_ID")],
              "TARGET",TRUE)

iv

````
####As ACC_OPN_DATE is suspicious we will remove this as well from IV

```{r}
library(devtools)
library(woe)

iv.plot.summary(iv.mult(LR_DF[,!names(LR_DF) %in% c("CUST_ID","ACC_OP_DATE")],
                        "TARGET",TRUE, verbose = FALSE))

iv <- iv.mult(LR_DF[,!names(LR_DF) %in% c("CUST_ID","ACC_OP_DATE")],
              "TARGET",TRUE)

iv

````
####Since there are no strong variables, we will use all of the variables which have average strength along with Balance and Occupation


##Check Hypothesis using Visualization
####Below code is used to generate decile for all numeric variables and the draw the visualizations

```{r}
library(data.table)
source("C:/Users/vasistas/Documents/From_Mydownloads/PGP-BDA/In_class/3rd_Residency/Rajesh_SL/Linear_Regression/Visualization.R")
output_folder = ("C:/Users/vasistas/Documents/From_Mydownloads/PGP-BDA/In_class/3rd_Residency/Assignments/Target/")
Target_var_name = "TARGET"

col_list = colnames(LR_DF)[
  lapply(LR_DF, class) %in% c("numeric", "integer")
  ]
col_list
for (i in 1 : length(col_list)) {
  fn_biz_viz(df = LR_DF, target = Target_var_name, var = col_list[i])
}

```





###Split dataset in Dev-Val-Hold Out samples  

```{r}
##Making the Occupation as Character
LR_DF$OCCUPATION <- as.character(LR_DF$OCCUPATION)
mydata <- LR_DF
View(mydata)

mydata$random <- runif(nrow(mydata), 0, 1)
mydata.dev <- mydata[which(mydata$random <= 0.5),]
mydata.val <- mydata[which(mydata$random > 0.5 
                           & mydata$random <= 0.8 ),]
mydata.hold <- mydata[which(mydata$random > 0.8),]
nrow(mydata)
nrow(mydata.dev)
nrow(mydata.val)
nrow(mydata.hold)
sum(mydata$TARGET) / nrow(mydata)
sum(mydata.dev$TARGET)/ nrow(mydata.dev)
sum(mydata.val$TARGET)/ nrow(mydata.val)
sum(mydata.hold$TARGET)/ nrow(mydata.hold)


````
##Build Logistics Regression Model on Dev  

```{r}
mylogit <- glm(
  TARGET ~  HOLDING_PERIOD +NO_OF_L_DR_TXNS+   TOT_NO_OF_L_TXNS
  + NO_OF_ATM_DR_TXNS + NO_OF_L_CR_TXNS+NO_OF_CHQ_DR_TXNS+  AMT_CHQ_DR+AMT_L_DR+BAL_CAP + OCCUPATION, 
  data = mydata.dev, family = "binomial"
)

summary(mylogit)


```
##From p-values we need to remove NO_OF_L_DR_TXNS,NO_OF_L_CR_TXNS and do the modelling again


```{r}
mylogit <- glm(
  TARGET ~  HOLDING_PERIOD + TOT_NO_OF_L_TXNS
  + NO_OF_ATM_DR_TXNS + NO_OF_CHQ_DR_TXNS+  AMT_CHQ_DR+AMT_L_DR+BAL_CAP + OCCUPATION, 
  data = mydata.dev, family = "binomial"
)

summary(mylogit)


```
###Still p value of OCCUPATIONSENP is high so treat Occupation variable

```{r}
pp <- as.data.frame.matrix(table(mydata.dev$OCCUPATION, mydata.dev$TARGET))
pp$total <- (pp$`0` + pp$`1`)
pp$rrate <- round(pp$`1` * 100 / (pp$`0` + pp$`1`), 3)
pp


```
#### Response rate of SAL and SENP is almost similar so we will club both of them and create a new category of SAL-SENP

```{r}
mydata.dev$DV_OCC = ifelse(mydata.dev$OCCUPATION %in% c("SAL", "SENP"),"SAL-SENP",mydata.dev$OCCUPATION)

 
table(mydata.dev$DV_OCC)



```

####Running the model again
```{r}
## After creating new Derived Occupation Categories
mylogit <- glm(
  TARGET ~  HOLDING_PERIOD +   TOT_NO_OF_L_TXNS
  + NO_OF_ATM_DR_TXNS +  AMT_CHQ_DR+AMT_L_DR+BAL_CAP + DV_OCC, 
  data = mydata.dev, family = "binomial"
)

summary(mylogit)






````
####Now all p values look under the limit of alpha which is 0.05

##Ensure No Multi Collinearity between variables

```{r}
library(car)
vif(mylogit)



```
###All values are below 2(GVIF^(1/(2*Df)) value) so no problem of Multi Collinearity


##Check Model Performance Measures
```{r}
## Rank Ordering Test
## Calculating the probabilities and create deciles
View(mydata.dev)
mydata.dev$prob <- predict(mylogit, mydata.dev, type="response")
mydata.dev$deciles <- decile(mydata.dev$prob)
class(mydata.dev)
##install.packages("data.table")
##install.packages("scales")
library(data.table)
library(scales)

tmp_DT = data.table(mydata.dev)
rank <- tmp_DT[, list(
  cnt = length(TARGET), 
  cnt_resp = sum(TARGET), 
  cnt_non_resp = sum(TARGET == 0)) , 
  by=deciles][order(-deciles)]
rank$rrate <- round (rank$cnt_resp / rank$cnt,3);
rank$cum_resp <- cumsum(rank$cnt_resp)
rank$cum_non_resp <- cumsum(rank$cnt_non_resp)
rank$cum_rel_resp <- round(rank$cum_resp / sum(rank$cnt_resp),3);
rank$cum_rel_non_resp <- round(rank$cum_non_resp / sum(rank$cnt_non_resp),3);
rank$ks <- percent(abs(rank$cum_rel_resp - rank$cum_rel_non_resp));
rank$rrate <- percent(rank$rrate)
rank$cum_rel_resp <- percent(rank$cum_rel_resp)
rank$cum_rel_non_resp <- percent(rank$cum_rel_non_resp)

View(rank)
library(knitr)
kable(rank,caption = "Rank Ordering table with KS score")


```

####As seen from Rank data frame, KS score is around 26%


###Check Model Goodness of fit
```{r}
############ Goodness of Fit: ##############

head(mydata.dev)
ttt <- data.table(mydata.dev)
library(sqldf)
sqldf('select deciles, count(1) as cnt_cust,
      sum(Target) as cnt_resp,
      sum(prob) as est_rep
      from ttt
      group by deciles'
)

hosmerlem <-
  function (y, yhat, g = 10) 
  {
    cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0, 
                                                             1, 1/g)), include.lowest = T)
    obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
    expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
    chisq <- sum((obs - expect)^2/expect)
    P <- 1 - pchisq(chisq, g - 2)
    c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
  }


hl_gof = hosmerlem(mydata.dev$TARGET, mydata.dev$prob )
hl_gof




```
####Goodness of fit data is shown above, p-value is shown above

###Check Model Concordance

```{r}
concordance=function(y, yhat)
{
  Con_Dis_Data = cbind(y, yhat) 
  ones = Con_Dis_Data[Con_Dis_Data[,1] == 1,]
  zeros = Con_Dis_Data[Con_Dis_Data[,1] == 0,]
  conc=matrix(0, dim(zeros)[1], dim(ones)[1])
  disc=matrix(0, dim(zeros)[1], dim(ones)[1])
  ties=matrix(0, dim(zeros)[1], dim(ones)[1])
  for (j in 1:dim(zeros)[1])
  {
    for (i in 1:dim(ones)[1])
    {
      if (ones[i,2]>zeros[j,2])
      {conc[j,i]=1}
      else if (ones[i,2]<zeros[j,2])
      {disc[j,i]=1}
      else if (ones[i,2]==zeros[j,2])
      {ties[j,i]=1}
    }
  }
  Pairs=dim(zeros)[1]*dim(ones)[1]
  PercentConcordance=(sum(conc)/Pairs)*100
  PercentDiscordance=(sum(disc)/Pairs)*100
  PercentTied=(sum(ties)/Pairs)*100
  return(list("Percent Concordance"=PercentConcordance,"Percent Discordance"=PercentDiscordance,"Percent Tied"=PercentTied,"Pairs"=Pairs))
}


concordance_output = concordance(mydata.dev$TARGET, mydata.dev$prob)
concordance_output


```

###Gini Index

```{r}
mydata.dev$Class = ifelse (mydata.dev$prob>0.2, 1, 0)
table(mydata.dev$TARGET, mydata.dev$Class)
##library(sqldf)
##sqldf('select deciles, count(1) as cnt, 
##    sum(Target) as Obs_Resp, 
##    count(Target==0) as Obs_Non_Resp, 
##    sum(prob) as Exp_Resp,
##    sum(1-prob) as Exp_Non_Resp 
##    from test
##    group by deciles
##    order by deciles desc')



############ GINI Index ##############
library(ineq)
gini = ineq(mydata.dev$prob, type="Gini")
gini



```

###AUC under ROCR
```{r}
### Calculating AUC using ROC Curve and KS for the model
##install.packages("ROCR")
library(ROCR)
pred <- prediction(mydata.dev$prob, mydata.dev$TARGET)
perf <- performance(pred, "tpr", "fpr")
plot(perf, col="green", lwd=2, main="ROC Curve")
abline(a=0,b=1,lwd=2,lty=2,col="gray")

KS <- max(attr(perf, 'y.values')[[1]]-attr(perf, 'x.values')[[1]])
auc <- performance(pred,"auc"); 
auc <- as.numeric(auc@y.values)
KS
auc



```

##Validate the Model

```{r}

mydata.val$DV_OCC = ifelse(mydata.val$OCCUPATION %in% c("SAL", "SENP"),"SAL-SENP",mydata.val$OCCUPATION)


mylogit_val <- glm(
  TARGET ~  HOLDING_PERIOD +   TOT_NO_OF_L_TXNS
  + NO_OF_ATM_DR_TXNS +  AMT_CHQ_DR+AMT_L_DR+BAL_CAP + DV_OCC, 
  data = mydata.val, family = "binomial"
)

summary(mylogit_val)

```




##Check Model Performance Measures for mydata.val
```{r}
## Rank Ordering Test
## Calculating the probabilities and create deciles
mydata.val$prob <- predict(mylogit_val, mydata.val, type="response")
mydata.val$deciles <- decile(mydata.val$prob)
class(mydata.val)
##install.packages("data.table")
##install.packages("scales")
library(data.table)
library(scales)

tmp_DT = data.table(mydata.val)
rank <- tmp_DT[, list(
  cnt = length(TARGET), 
  cnt_resp = sum(TARGET), 
  cnt_non_resp = sum(TARGET == 0)) , 
  by=deciles][order(-deciles)]
rank$rrate <- round (rank$cnt_resp / rank$cnt,3);
rank$cum_resp <- cumsum(rank$cnt_resp)
rank$cum_non_resp <- cumsum(rank$cnt_non_resp)
rank$cum_rel_resp <- round(rank$cum_resp / sum(rank$cnt_resp),3);
rank$cum_rel_non_resp <- round(rank$cum_non_resp / sum(rank$cnt_non_resp),3);
rank$ks <- percent(abs(rank$cum_rel_resp - rank$cum_rel_non_resp));
rank$rrate <- percent(rank$rrate)
rank$cum_rel_resp <- percent(rank$cum_rel_resp)
rank$cum_rel_non_resp <- percent(rank$cum_rel_non_resp)

View(rank)
library(knitr)
kable(rank,caption = "Rank Ordering table with KS score")


```

####KS score is around 26%


###Check Model Goodness of fit
```{r}
############ Goodness of Fit: ##############
head(mydata.val)
ttt <- data.table(mydata.val)
library(sqldf)
sqldf('select deciles, count(1) as cnt_cust,
      sum(Target) as cnt_resp,
      sum(prob) as est_rep
      from ttt
      group by deciles'
)

hosmerlem <-
  function (y, yhat, g = 10) 
  {
    cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0, 
                                                             1, 1/g)), include.lowest = T)
    obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
    expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
    chisq <- sum((obs - expect)^2/expect)
    P <- 1 - pchisq(chisq, g - 2)
    c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
  }


hl_gof = hosmerlem(mydata.val$TARGET, mydata.val$prob )
hl_gof




```
####Goodness of fit data is shown above, p-value is shown above

###Check Model Concordance

```{r}
concordance=function(y, yhat)
{
  Con_Dis_Data = cbind(y, yhat) 
  ones = Con_Dis_Data[Con_Dis_Data[,1] == 1,]
  zeros = Con_Dis_Data[Con_Dis_Data[,1] == 0,]
  conc=matrix(0, dim(zeros)[1], dim(ones)[1])
  disc=matrix(0, dim(zeros)[1], dim(ones)[1])
  ties=matrix(0, dim(zeros)[1], dim(ones)[1])
  for (j in 1:dim(zeros)[1])
  {
    for (i in 1:dim(ones)[1])
    {
      if (ones[i,2]>zeros[j,2])
      {conc[j,i]=1}
      else if (ones[i,2]<zeros[j,2])
      {disc[j,i]=1}
      else if (ones[i,2]==zeros[j,2])
      {ties[j,i]=1}
    }
  }
  Pairs=dim(zeros)[1]*dim(ones)[1]
  PercentConcordance=(sum(conc)/Pairs)*100
  PercentDiscordance=(sum(disc)/Pairs)*100
  PercentTied=(sum(ties)/Pairs)*100
  return(list("Percent Concordance"=PercentConcordance,"Percent Discordance"=PercentDiscordance,"Percent Tied"=PercentTied,"Pairs"=Pairs))
}

concordance_output = concordance(mydata.val$TARGET, mydata.val$prob)
concordance_output


```

###Gini Index

```{r}
mydata.val$Class = ifelse (mydata.val$prob>0.2, 1, 0)
table(mydata.val$TARGET, mydata.val$Class)
##library(sqldf)
##sqldf('select deciles, count(1) as cnt, 
##    sum(Target) as Obs_Resp, 
##    count(Target==0) as Obs_Non_Resp, 
##    sum(prob) as Exp_Resp,
##    sum(1-prob) as Exp_Non_Resp 
##    from test
##    group by deciles
##    order by deciles desc')



############ GINI Index ##############
library(ineq)
gini = ineq(mydata.val$prob, type="Gini")
gini



```

###AUC under ROCR
```{r}
### Calculating AUC using ROC Curve and KS for the model
##install.packages("ROCR")
library(ROCR)
pred <- prediction(mydata.val$prob, mydata.val$TARGET)
perf <- performance(pred, "tpr", "fpr")
plot(perf, col="green", lwd=2, main="ROC Curve")
abline(a=0,b=1,lwd=2,lty=2,col="gray")

KS <- max(attr(perf, 'y.values')[[1]]-attr(perf, 'x.values')[[1]])
auc <- performance(pred,"auc"); 
auc <- as.numeric(auc@y.values)
KS
auc



```


##Validate the Model on Hold data set

```{r}

mydata.hold$DV_OCC = ifelse(mydata.hold$OCCUPATION %in% c("SAL", "SENP"),"SAL-SENP",mydata.hold$OCCUPATION)


mylogit_hold <- glm(
  TARGET ~  HOLDING_PERIOD +   TOT_NO_OF_L_TXNS
  + NO_OF_ATM_DR_TXNS +  AMT_CHQ_DR+AMT_L_DR+BAL_CAP + DV_OCC, 
  data = mydata.hold, family = "binomial"
)

summary(mylogit_hold)

```

```{r}
## Rank Ordering Test
## Calculating the probabilities and create deciles
mydata.hold$prob <- predict(mylogit_hold, mydata.hold, type="response")
mydata.hold$deciles <- decile(mydata.hold$prob)
class(mydata.hold)
##install.packages("data.table")
##install.packages("scales")
library(data.table)
library(scales)

tmp_DT = data.table(mydata.hold)
rank <- tmp_DT[, list(
  cnt = length(TARGET), 
  cnt_resp = sum(TARGET), 
  cnt_non_resp = sum(TARGET == 0)) , 
  by=deciles][order(-deciles)]
rank$rrate <- round (rank$cnt_resp / rank$cnt,3);
rank$cum_resp <- cumsum(rank$cnt_resp)
rank$cum_non_resp <- cumsum(rank$cnt_non_resp)
rank$cum_rel_resp <- round(rank$cum_resp / sum(rank$cnt_resp),3);
rank$cum_rel_non_resp <- round(rank$cum_non_resp / sum(rank$cnt_non_resp),3);
rank$ks <- percent(abs(rank$cum_rel_resp - rank$cum_rel_non_resp));
rank$rrate <- percent(rank$rrate)
rank$cum_rel_resp <- percent(rank$cum_rel_resp)
rank$cum_rel_non_resp <- percent(rank$cum_rel_non_resp)

View(rank)
library(knitr)
kable(rank,caption = "Rank Ordering table with KS score")


```




###Check Model Goodness of fit for hold dataset
```{r}
############ Goodness of Fit: ##############
head(mydata.hold)
ttt <- data.table(mydata.hold)
library(sqldf)
sqldf('select deciles, count(1) as cnt_cust,
      sum(Target) as cnt_resp,
      sum(prob) as est_rep
      from ttt
      group by deciles'
)

hosmerlem <-
  function (y, yhat, g = 10) 
  {
    cutyhat <- cut(yhat, breaks = quantile(yhat, probs = seq(0, 
                                                             1, 1/g)), include.lowest = T)
    obs <- xtabs(cbind(1 - y, y) ~ cutyhat)
    expect <- xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
    chisq <- sum((obs - expect)^2/expect)
    P <- 1 - pchisq(chisq, g - 2)
    c("X^2" = chisq, Df = g - 2, "P(>Chi)" = P)
  }


hl_gof = hosmerlem(mydata.hold$TARGET, mydata.hold$prob )
hl_gof




```
####Goodness of fit data is shown above, p-value is shown above

###Check Model Concordance

```{r}
concordance=function(y, yhat)
{
  Con_Dis_Data = cbind(y, yhat) 
  ones = Con_Dis_Data[Con_Dis_Data[,1] == 1,]
  zeros = Con_Dis_Data[Con_Dis_Data[,1] == 0,]
  conc=matrix(0, dim(zeros)[1], dim(ones)[1])
  disc=matrix(0, dim(zeros)[1], dim(ones)[1])
  ties=matrix(0, dim(zeros)[1], dim(ones)[1])
  for (j in 1:dim(zeros)[1])
  {
    for (i in 1:dim(ones)[1])
    {
      if (ones[i,2]>zeros[j,2])
      {conc[j,i]=1}
      else if (ones[i,2]<zeros[j,2])
      {disc[j,i]=1}
      else if (ones[i,2]==zeros[j,2])
      {ties[j,i]=1}
    }
  }
  Pairs=dim(zeros)[1]*dim(ones)[1]
  PercentConcordance=(sum(conc)/Pairs)*100
  PercentDiscordance=(sum(disc)/Pairs)*100
  PercentTied=(sum(ties)/Pairs)*100
  return(list("Percent Concordance"=PercentConcordance,"Percent Discordance"=PercentDiscordance,"Percent Tied"=PercentTied,"Pairs"=Pairs))
}
concordance_output = concordance(mydata.hold$TARGET, mydata.hold$prob)
concordance_output


```

###Gini Index

```{r}
mydata.hold$Class = ifelse (mydata.hold$prob>0.2, 1, 0)
table(mydata.hold$TARGET, mydata.hold$Class)
##library(sqldf)
##sqldf('select deciles, count(1) as cnt, 
##    sum(Target) as Obs_Resp, 
##    count(Target==0) as Obs_Non_Resp, 
##    sum(prob) as Exp_Resp,
##    sum(1-prob) as Exp_Non_Resp 
##    from test
##    group by deciles
##    order by deciles desc')



############ GINI Index ##############
library(ineq)
gini = ineq(mydata.hold$prob, type="Gini")
gini



```

###AUC under ROCR
```{r}
### Calculating AUC using ROC Curve and KS for the model
##install.packages("ROCR")
library(ROCR)
pred <- prediction(mydata.hold$prob, mydata.hold$TARGET)
perf <- performance(pred, "tpr", "fpr")
plot(perf, col="green", lwd=2, main="ROC Curve")
abline(a=0,b=1,lwd=2,lty=2,col="gray")

KS <- max(attr(perf, 'y.values')[[1]]-attr(perf, 'x.values')[[1]])
auc <- performance(pred,"auc"); 
auc <- as.numeric(auc@y.values)
KS
auc



```
